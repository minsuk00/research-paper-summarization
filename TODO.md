# Todo:
- Chatbot on one paper / multiple paper 조사 & 구현 (RAG)
- Finetuning 조사
- output text 길이 조절 조사 & 구현
- 논문 요약 원리 이해
- prompt engineering
- Evaluation metrics 조사 & 구현
- Preprocessing 
    - integrate reference text or not
    - which sections to choose?
    - extract images?
- Open Source 모델 조사 & 구현 (OpenAI/AWS랑 비교 / 가격 조사)
    - Amazon Titan
    - Meta Llama 2
    - Cohere Command & Embed
    - Anthropic Claude
    - AI21 Labs Jurassic
    - gpt different versions
- choose which model to use


# Things to talk about: 
- evaluation metrics (concern: how well they work?)
- apis
- claude -> token limit very high

# Questions:
- Fact checking data generated by LLM -> who? how?
- MLab_pyalex -> difference?
- Rag implementation that I can use?
- how is rei handling evaluation?
- Using qdrant api (response out of range? regex)
- llama 2 no commercial use?
    - The Llama 2 license permits any commercial use of the model with one small exception – if you had a user count of over 700 million per month at the time of the model's launch, obligatory permission must be sought from Meta.
- if local llm, how?
- offline meeting / work?
- feedback (compare outputs e.g. different preprocessing / model / etc)

# 다음 할것:
- 회의 준비
- generate summary api 구현
- evaluation api 구현 및 점수 이해
- Open Source 모델 조사 / OpenAI, AWS 가격 비교
- 논문 preprocessing 조사